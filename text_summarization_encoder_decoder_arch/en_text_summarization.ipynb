{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9812e015",
   "metadata": {},
   "source": [
    "# load summerization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54359c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101c697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"billsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19048ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary', 'title'],\n",
       "        num_rows: 18949\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary', 'title'],\n",
       "        num_rows: 3269\n",
       "    })\n",
       "    ca_test: Dataset({\n",
       "        features: ['text', 'summary', 'title'],\n",
       "        num_rows: 1237\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca79f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train']\n",
    "test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f957fbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Column'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5bc9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561\n"
     ]
    }
   ],
   "source": [
    "print(len(train['summary'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8e4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = '<sos>'\n",
    "eos_token = '<eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(data,sos_token,eos_token):\n",
    "    text_tokens = nltk.word_tokenize(data['text'])\n",
    "    summarized_tokens = nltk.word_tokenize(data['summary'])\n",
    "    text_tokens = [sos_token] + text_tokens + [eos_token]\n",
    "    summarized_tokens = [sos_token] + summarized_tokens + [eos_token]\n",
    "    return {'text_tokens':text_tokens,'summary_tokens':summarized_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91ede55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_kwargs = {\n",
    "    'sos_token':sos_token,\n",
    "    'eos_token':eos_token,\n",
    "}\n",
    "train = train.map(tokenizer,fn_kwargs=fn_kwargs)\n",
    "test = test.map(tokenizer,fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26b0614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2954"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['text_tokens'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0afe9153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "def build_vocab(sentences):\n",
    "    # counter = Counter([token for tokens in sentences for token in tokens])\n",
    "    idx = 2  \n",
    "    vocab = {'<unk>':0,'<pad>':1}\n",
    "    for tokens in sentences:\n",
    "        for token in tokens:\n",
    "            if token in vocab.keys():\n",
    "                continue\n",
    "            vocab[token] = idx \n",
    "            idx += 1\n",
    "            \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fd219c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq,pad,max_length):\n",
    "    if(len(seq)>max_length):\n",
    "        return seq[:max_length]\n",
    "    return seq + [pad]*(max_length-len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8f21a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word2index(vocab,tokens):\n",
    "    tokens_indexes = []\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "            tokens_indexes.append(vocab[token])\n",
    "        else:\n",
    "            tokens_indexes.append(vocab['<unk>'])\n",
    "    return tokens_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d13bf952",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train['text_tokens']\n",
    "summaries = train['summary_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82118dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e217c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [convert_word2index(vocab,pad_seq(tokens,'<pad>',2000)) for tokens in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee28f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af96ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [convert_word2index(vocab,pad_seq(tokens,'<pad>',1000)) for tokens in summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b75cc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test['text_tokens']\n",
    "test_summary = test['summary_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0802a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_idxes = [convert_word2index(vocab,pad_seq(tokens,'<pad>',2000)) for tokens in test_text]\n",
    "test_summary_idxes = [convert_word2index(vocab,pad_seq(tokens,'<pad>',1000)) for tokens in test_summary]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0aaec",
   "metadata": {},
   "source": [
    "# DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7c3244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5a408a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSummary(Dataset):\n",
    "    def __init__(self,text_idxes,summaries_idxs):\n",
    "        self.text_idxes = text_idxes \n",
    "        self.summaries_idxs = summaries_idxs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_idxes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.text_idxes[index], dtype=torch.long), torch.tensor(self.summaries_idxs[index], dtype=torch.long)\n",
    "\n",
    "    \n",
    "\n",
    "text_summary = TextSummary(text_idxes = texts , summaries_idxs = summaries)\n",
    "train_dataloader = DataLoader(text_summary , batch_size=32 , shuffle= True)\n",
    "test_text_summary = TextSummary(text_idxes= test_text_idxes,summaries_idxs=test_summary_idxes)\n",
    "test_dataloader = DataLoader(test_text_summary,batch_size=32,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a177eef6",
   "metadata": {},
   "source": [
    "# building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ffb7bb",
   "metadata": {},
   "source": [
    "## encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e0e8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class encoder(torch.nn.Module):\n",
    "    def __init__(self,input_dim,embedding_dim,hidden_dim,dropout,num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(input_dim,embedding_dim)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim,hidden_size=hidden_dim,num_layers=num_layers,dropout=dropout)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        embedding_input = self.dropout(self.embedding(X))\n",
    "        outputs,(hidden,cell) = self.lstm(embedding_input)\n",
    "        return hidden,cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640c688",
   "metadata": {},
   "source": [
    "## decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caccac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(torch.nn.Module):\n",
    "    def __init__(self,output_dim,embedding_dim,hidden_dim,dropout,num_layers):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embbedding = torch.nn.Embedding(output_dim,embedding_dim)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim,hidden_size=hidden_dim,num_layers=num_layers,dropout=dropout)\n",
    "        self.fc1 = torch.nn.Linear(embedding_dim,output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,X,prev_hidden,prev_cell):\n",
    "        embedding_input = self.dropout(self.embedding(X.unsqueeze(0)))\n",
    "        outputs,(hidden,cell) = self.lstm(embedding_input)\n",
    "        prediction = self.fc1(outputs.squeeze(0))\n",
    "        return hidden,cell,prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c59ef",
   "metadata": {},
   "source": [
    "# seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b40c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq(torch.nn.Module):\n",
    "    def __init__(self,encoder,decoder,device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self,X,target,teaching_force_ratio):\n",
    "        hidden,cell = self.encoder(X)\n",
    "        decoder_input = target[0,:]\n",
    "        output_dim = self.decoder.output_dim\n",
    "        batch_size = target.shape[1]\n",
    "        target_size = target.shape[0]\n",
    "        outputs = torch.zeros(target_size,batch_size,output_dim).to(self.device)\n",
    "\n",
    "        for t in range(1,len(target_size)):\n",
    "            output,hidden,cell = self.decoder(decoder_input,hidden,cell)\n",
    "            outputs[t] = output\n",
    "            teaching_force = random.random() < teaching_force_ratio\n",
    "            top1 = output.argemax(1)\n",
    "            decoder_input = target[t] if teaching_force else top1 \n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603d7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
