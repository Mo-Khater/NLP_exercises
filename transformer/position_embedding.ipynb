{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e7387b",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "575ef3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_sentences(\n",
    "  vocab, \n",
    "  num_sentences, \n",
    "  max_sentence_length\n",
    ") -> list[str]:\n",
    "\n",
    "    sentences = []\n",
    "    for _ in range(num_sentences):\n",
    "        sentence_length = random.randint(3, max_sentence_length)\n",
    "        sentence = \" \".join(random.choices(vocab, k=sentence_length))\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d00a9398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat rug on on over jumps sat runs mat\n",
      "the sat dog cat dog on the sat dog\n",
      "jumps the rug cat quickly runs\n",
      "lay lay rug over jumps quickly dog quickly the rug\n",
      "runs sat sat the runs dog\n"
     ]
    }
   ],
   "source": [
    " # Define a vocabulary of words\n",
    "vocab = [\n",
    "    'the', 'cat', 'sat', 'on', 'mat', 'dog', 'lay', 'rug', \n",
    "    'runs', 'quickly', 'jumps', 'over'\n",
    "]\n",
    "\n",
    "# Number of sentences to generate\n",
    "num_sentences = 10000\n",
    "\n",
    "# Maximum length of each sentence\n",
    "max_sentence_length = 10\n",
    "\n",
    "# Generate synthetic sentences\n",
    "sentences = generate_synthetic_sentences(\n",
    "    vocab,\n",
    "    num_sentences,\n",
    "    max_sentence_length\n",
    ")\n",
    "\n",
    "# Print a few generated sentences\n",
    "for i in range(5):\n",
    "    print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0813047",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "index_to_word = {i: word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3c31e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_indices(sentence):\n",
    "    return [word_to_index[word] for word in sentence.split()]\n",
    "\n",
    "sequences = [sentence_to_indices(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671952aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "target_words = []\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(len(seq) - 1):\n",
    "        input_sequences.append(seq[:i+1])\n",
    "        target_words.append(seq[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68843ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = [seq + [0]*(max_len - len(seq)) for seq in input_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568879fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences_tensor= torch.tensor(input_sequences, dtype=torch.long)\n",
    "target_words_tensor= torch.tensor(target_words, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d71b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8391803",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b77d172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_len) -> None:\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.position_embeddings = nn.Embedding(max_len, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        seq_length = x.size(1)\n",
    "        word_emb = self.word_embeddings(x)\n",
    "        # word_emb [batch_size,seq_length,emb_dim]\n",
    "        positions = torch.arange(0, seq_length, device=x.device).unsqueeze(0)\n",
    "        pos_emb = self.position_embeddings(positions)\n",
    "        # pos_emb [1,seq_length,emb_dim]\n",
    "        combined_emb = word_emb + pos_emb\n",
    "        # combined_emb [batch_size,seq_length,emb_dim]\n",
    "        pooled = combined_emb.mean(dim=1)\n",
    "        # pooled [batch_size,emb_dim]\n",
    "        output = self.linear(pooled)\n",
    "        # pooled [batch_size,vocab_size]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f695d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.5265\n",
      "Epoch 2/10, Loss: 2.5253\n",
      "Epoch 3/10, Loss: 2.5242\n",
      "Epoch 4/10, Loss: 2.5230\n",
      "Epoch 5/10, Loss: 2.5220\n",
      "Epoch 6/10, Loss: 2.5209\n",
      "Epoch 7/10, Loss: 2.5199\n",
      "Epoch 8/10, Loss: 2.5189\n",
      "Epoch 9/10, Loss: 2.5179\n",
      "Epoch 10/10, Loss: 2.5169\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleLM(vocab_size, embedding_dim, max_len)\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs: int = 10 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_sequences_tensor)\n",
    "    loss = criterion(outputs, target_words_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29c4a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embeddings= model.position_embeddings.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfc928cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.1340306   0.11033292  0.22841862  0.11904594  0.03617826  1.5396925\n",
      "  -0.23890209  0.511333    0.03775401  0.75233614]\n",
      " [ 1.2807093  -0.9325126  -1.2030383   0.49914822  0.2410827  -0.98017025\n",
      "   0.26483223  0.43462896  0.10837775  1.0033818 ]\n",
      " [ 0.81870496  1.9024105   0.48907223 -1.08184     0.10827861 -0.34640405\n",
      "   1.263768    1.6890718   0.5562738  -0.03814454]\n",
      " [-0.16376473  0.48563674 -0.13159533  0.29760948 -0.8620853  -0.7046244\n",
      "   1.950941   -0.24978565  0.5007888  -0.7222857 ]\n",
      " [-1.5125744   0.91639096  0.47649866  0.65601915 -0.25429332 -1.3177302\n",
      "  -0.6660218   0.9739118   1.0674806   0.7716453 ]\n",
      " [-1.0245352   2.9435475   1.1478709   1.5670217  -0.7481856   1.0309759\n",
      "   0.4723779  -0.0290156  -0.5433204  -0.48901293]\n",
      " [ 0.21585585 -1.8701496  -0.7799847  -0.08169478 -0.74236745 -0.35431692\n",
      "  -1.2548198  -1.4870505   0.61008084 -0.96681476]\n",
      " [-1.269984   -0.03000763  0.32594803  1.4416723   1.9523418  -1.0127788\n",
      "  -1.2961525  -2.7342653   0.11808898  1.4207361 ]\n",
      " [ 0.0470973  -1.1320602   1.0101594   0.72313637  2.2614188   1.4250985\n",
      "   0.28511667  1.6327889  -0.5449078   0.34053376]]\n"
     ]
    }
   ],
   "source": [
    "print(position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c7bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
